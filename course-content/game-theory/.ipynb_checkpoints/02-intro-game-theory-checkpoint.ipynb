{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Game Theory\n",
    "\n",
    "A *game* refers to any interactive situation involving a group of  \"self-interested\" agents, or players. The defining feature of a game is that the players are engaged in an\n",
    "\"interdependent decision problem\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make graphs look nice\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The  mathematical description of a game includes at least the following components: \n",
    "\n",
    "\n",
    "1. The *players*. In this entry, we only consider games with finitely many players. We use $N$ to denote the set of players in a game. \n",
    "\n",
    "2. For each player $i\\in N$, a finite set of *feasible* options (typically called *actions* or *strategies*).\n",
    "\n",
    "3. For each player $i\\in N$, a  *preference* over the possible outcomes of the game. The standard approach in game theory is to represent  each player's preference as a (von Neumann-Morgenstern) utility function that assigns a real number to each outcome of the game. \n",
    "\n",
    "\n",
    "A game may represent other features of the strategic situation. For instance,  some games represent multi-stage decision problems which may include simultaneous or stochastic moves.   For simplicity, we  start with games that involve  players making a single decision simultaneously without stochastic moves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "A **game in strategic form** is a tuple $\\langle N, (S_i)_{i\\in N}, (u_i)_{i\\in N}\\rangle$ where:\n",
    "\n",
    "\n",
    "1. $N$ is a finite non-empty set\n",
    "2. For each $i\\in N$, $S_i$ is a finite non-empty set\n",
    "3. For each $i\\in N$, $u_i:\\times_iS_i \\rightarrow\\mathbb{R}$ is player $i$'s utility. \n",
    "\n",
    "\n",
    " The elements of  $\\times_{i\\in N} S_i$ are the outcomes of the game and are called **strategy profiles**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In most games, no single player has total control over which outcome\n",
    " will be realized at the end of the interaction. The outcome of a game depends on the\n",
    "decisions of <em>all players</em>. \n",
    "\n",
    "\n",
    "The central analytic tool of classical game theory are **solution\n",
    "concepts**. A solution concept associates a set of outcomes (i.e., a set of strategy profiles) with each game (from some fixed class of games). \n",
    "\n",
    "From a prescriptive point of view,  a  solution concept is a recommendation about what the players should do in a game, or about what outcomes can be expected assuming that the players choose *rationally*.  From a predictive point of view, solution concepts describe what the players will actually do in a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nash Equilibrium \n",
    "\n",
    "Let $G=\\langle N, (S_i)_{i\\in N}, (u_i)_{i\\in N}\\rangle$ be a finite strategic game (each $S_i$ is finite and the set of players $N$ is finite). \n",
    "\n",
    "A **strategy profile** is an element $\\times_{i\\in N} S_i$\n",
    "\n",
    "Given a strategy profile $\\sigma\\in \\times_{i\\in N}S_i$, $\\sigma_{-i}$ is an element of \n",
    "$$ S_1\\times S_2\\times\\cdots S_{i-1}\\times S_{i+1}\\times \\cdots S_n$$\n",
    "\n",
    "\n",
    "A strategy profiel $\\sigma$ is a **pure strategy Nash equilibrium** provided that for all $i\\in N$, for all $a\\in S_i$, \n",
    "$$u_i(\\sigma) \\ge u_i(a, \\sigma_{-i})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pure Coordination Game\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(1, 1)$ | $(0, 0)$|\n",
    "|$S2$ |$(0, 0)$ | $(1, 1)$|\n",
    "\n",
    "There are two pure strategy Nash equilibria: $(S1, S1)$ and $(S2, S2)$\n",
    "\n",
    "> The basic intellectual premise, or working hypothesis, for rational players in this game seems to be the premise that some rule must be used if success is to exceed coincidence, and that the best rule to be found, whatever its rationalization, is consequently a rational rule. (T. Schelling, *The Strategy of Conflict*, pg. 283)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hi-Lo Game\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(3, 3)$ | $(0, 0)$|\n",
    "|$S2$ |$(0, 0)$ | $(1, 1)$|\n",
    "\n",
    "There are two pure strategy Nash equilibria: $(S1, S1)$ and $(S2, S2)$\n",
    "\n",
    "> There are these two broad empirical facts about Hi-Lo games, people almost\n",
    "always choose [$S1$] and people with common knowledge of each other's rationality think it is\n",
    "obviously rational to choose [$S1$].\" (M. Bacharach, *Beyond Individual Choice*, p. 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matching Pennies\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(1, -1)$ | $(-1, 1)$|\n",
    "|$S2$ |$(-1, 1)$ | $(1, -1)$|\n",
    "\n",
    "There are no pure strategy Nash equilibria.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A **mixed strategy** for player $i$ in a finite game $\\langle N, (S_i)_{i\\in N}, (u_i)_{i\\in N}\\rangle$ is a lottery  on $S_i$, i.e., a probability over player $i$'s strategies. \n",
    "\n",
    "![mixed-strat.jpg](mixed-strat.jpg)\n",
    "\n",
    "The utilities for a mixed strategy profile $(p, q)$ is: \n",
    "\n",
    "$$\\mbox{Row}: p(1-q) -pq - (1-p)(1-q)  + (1-p)q$$\n",
    "$$\\mbox{Col}: -p(1-q) +pq + (1-p)(1-q)  - (1-p)q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> We are reluctant to believe that our decisions are made at random.   We prefer to be able to point to a reason for each action we take.   Outside of Las Vegas we do not spin roulettes. (A. Rubinstein, Comments on the Interpretation of Game Theory, Econometrica 59, 909 - 924, 1991)\n",
    "\n",
    "\n",
    "What does it mean to play a mixed strategy? \n",
    "\n",
    "* Randomize to confuse your opponent (e.g., matching pennies games)\n",
    "* Players randomize when they are uncertain about the other’s action (e.g., battle of the sexes game)\n",
    "* Mixed strategies are a concise description of what might happen in repeated play\n",
    "* Mixed strategies describe population dynamics: After selecting 2 agents from a population, a mixed strategy is the probability of getting an agent who will play one pure strategy or another.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(1, -1)$ | $(-1, 1)$|\n",
    "|$S2$ |$(-1, 1)$ | $(1, -1)$|\n",
    "\n",
    "There is one mixed strategy Nash equilibria: $((1/2: S1, 1/2: S2), (1/2:S1, 1/2:S2))$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Battle of the Sexes\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(2, 1)$ | $(0, 0)$|\n",
    "|$S2$ |$(0, 0)$ | $(1, 2)$|\n",
    "\n",
    "There are two pure strategy Nash equilibrium $(S1, S1)$ and $(S2, S2)$ (and one mixed strategy Nash equilibrium).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stag Hunt\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(3, 3)$ | $(0, 2)$|\n",
    "|$S2$ |$(2, 0)$ | $(1, 1)$|\n",
    "\n",
    "There are two pure strategy Nash equilibrium $(S1, S1)$ and $(S2, S2)$. While $(S1, S1)$ Pareto dominates $(S1, S1)$, but $(S2, S2)$ is 'less risky'. \n",
    "\n",
    "> The problem of instituting, or improving, the social contract can be thought of as the problem of moving from riskless hunt hare equilibrium to the risky but rewarding stag hunt equilibrium. (B. Skyrms, *Stag Hunt and the Evolution of Social Structure*, p. 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prisoner's Dilemma\n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(3, 3)$ | $(0, 4)$|\n",
    "|$S2$ |$(4, 0)$ | $(1, 1)$|\n",
    "\n",
    "There is one Nash equilibrium $(S2, S2)$.  The non-equilibrium $(S1, S1)$ Pareto-dominates $(S2, S2)$. \n",
    "\n",
    "> Game theorists think it just plain wrong to claim that the Prisoners' Dilemma embodies the essence of the problem of human cooperation.  On the contrary, it represents a situation in which the dice are as loaded against the emergence of cooperation as they could possibly be.   If the great game of life played by the human species were the Prisoner's Dilemma, we wouldn't have evolved as social animals!....No paradox of rationality exists.   Rational players don't cooperate in the Prisoners' Dilemma, because the conditions necessary for rational cooperation are absent in this game. (K. Binmore, *Natural Justice*, p. 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Game Theory in Python\n",
    "\n",
    "* Gambit - [https://gambitproject.readthedocs.io/en/latest/index.html](https://gambitproject.readthedocs.io/en/latest/index.html):  a library of game theory software and tools for the construction and analysis of finite extensive and strategic games.\n",
    "* Nashpy - [https://nashpy.readthedocs.io/en/latest/](https://nashpy.readthedocs.io/en/latest/): a simple library used for the computation of equilibria in 2 player strategic form games.\n",
    "* Axelrod - [https://axelrod.readthedocs.io/en/stable/index.html](https://axelrod.readthedocs.io/en/stable/index.html): a library to study iterated prisoner's dilemma. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nashpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nashpy as nash\n",
    "import numpy as np\n",
    "\n",
    "#  Coordination Game\n",
    "A = np.array([[1, 0], [0, 1]])\n",
    "B = np.array([[1, 0], [0, 1]])\n",
    "coord = nash.Game(A, B)\n",
    "\n",
    "print(coord)\n",
    "\n",
    "print([1,2])\n",
    "print(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sigma1_r = [1, 0]\n",
    "sigma1_c = [0, 1]\n",
    "print(\"The utilities are \", coord[sigma1_r, sigma1_c])\n",
    "\n",
    "sigma2_r = [1 / 2, 1 / 2]\n",
    "sigma2_c = [1 / 2, 1 / 2]\n",
    "print(\"The utilities are \", coord[sigma2_r, sigma2_c])\n",
    "\n",
    "eqs = coord.support_enumeration()\n",
    "print(\"The Nash equilibria are:\")\n",
    "for ne in eqs:\n",
    "    print(\"\\t\", ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hi-Lo \n",
    "\n",
    "A = np.array([[3, 0], [0, 1]])\n",
    "B = np.array([[3, 0], [0, 1]])\n",
    "hilo = nash.Game(A, B)\n",
    "eqs = hilo.support_enumeration()\n",
    "print(\"The Nash equilibria for Hi-Lo are:\")\n",
    "for ne in eqs:\n",
    "    print(\"\\t\", ne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Battle of the Sexes\n",
    "\n",
    "A = np.array([[2, 0], [0, 1]])\n",
    "B = np.array([[1, 0], [0, 2]])\n",
    "bos = nash.Game(A, B)\n",
    "eqs = bos.support_enumeration()\n",
    "print(\"The Nash equilibria for Battle of the Sexes are:\")\n",
    "for ne in eqs:\n",
    "    print(\"\\t\", ne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Stag Hunt\n",
    "\n",
    "A = np.array([[3, 0], [2, 1]])\n",
    "B = np.array([[3, 2], [0, 1]])\n",
    "sh = nash.Game(A, B)\n",
    "\n",
    "eqs = sh.support_enumeration()\n",
    "print(\"The Nash equilibria for the Stag Hunt are:\")\n",
    "for ne in eqs:\n",
    "    print(\"\\t\", ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Prisoner's Dilemma \n",
    "\n",
    "A = np.array([[3, 0], [4, 1]])\n",
    "B = np.array([[3, 4], [0, 1]])\n",
    "pd = nash.Game(A, B)\n",
    "\n",
    "eqs = pd.support_enumeration()\n",
    "print(\"The Nash equilibria  for the Prisoner's Dilemma are:\")\n",
    "for ne in eqs:\n",
    "    print(\"\\t\", ne)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Axelrod\n",
    "\n",
    "[Axelrod](https://axelrod.readthedocs.io/en/stable/index.html) is a Python package to study repeated play of the Prisoner's Dilemma: \n",
    "\n",
    "| &nbsp;  |$S1$ | $S2$ |\n",
    "|----|----|----|\n",
    "|$S1$ |$(3, 3)$ | $(0, 4)$|\n",
    "|$S2$ |$(4, 0)$ | $(1, 1)$|\n",
    "\n",
    "There are different ways to repeat play of PD: \n",
    "\n",
    "1. Two players repeatedly playing a PD \n",
    "2. Multiple players repeatedly playing PD against each other \n",
    "3. Multiple players repeatedly playing PD against their neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Running a Match\n",
    "\n",
    "In a Match, two player repeatedly play a PD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import axelrod as axl\n",
    "\n",
    "players = (axl.Cooperator(), axl.Alternator())\n",
    "match = axl.Match(players, 5)\n",
    "\n",
    "print(\"Match Play: \", match.play())\n",
    "print(\"Match Scores: \", match.scores())\n",
    "print(\"Final Scores: \", match.final_score())\n",
    "print(\"Final Scores Per Turn: \", match.final_score_per_turn())\n",
    "print(\"Winner: \", match.winner())\n",
    "print(\"Cooperation: \", match.cooperation())\n",
    "print(\"Normalized Coperation: \", match.normalised_cooperation()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "players = (axl.Cooperator(),  axl.Random())\n",
    "match = axl.Match(players=players, turns=10, noise=0.0)\n",
    "match.play()  \n",
    "\n",
    "print(\"Match Scores: \", match.scores())\n",
    "print(\"Final Scores: \", match.final_score())\n",
    "print(\"Final Scores Per Turn: \", match.final_score_per_turn())\n",
    "print(\"Winner: \", match.winner())\n",
    "print(\"Cooperation: \", match.cooperation())\n",
    "print(\"Normalized Coperation: \", match.normalised_cooperation()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Running a Tournament\n",
    "\n",
    "In a tournament, each player plays every other player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "players = [axl.Cooperator(), axl.Defector(),\n",
    "           axl.TitForTat(), axl.Grudger()]\n",
    "tournament = axl.Tournament(players)\n",
    "results = tournament.play(progress_bar=False)\n",
    "print(\"Ranked players: \", results.ranked_names)\n",
    "print(\"Normalized Scores: \", results.normalised_scores  )\n",
    "print(\"Wins: \", results.wins)\n",
    "print(\"payoff matrix\")\n",
    "pprint.pprint(results.payoff_matrix);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot = axl.Plot(results)\n",
    "plot.boxplot();\n",
    "plot.winplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "players = [axl.Cooperator(), axl.Defector(),\n",
    "           axl.TitForTat(), axl.Grudger(), axl.Random()]\n",
    "\n",
    "tournament = axl.Tournament(players)\n",
    "results = tournament.play(progress_bar=False)\n",
    "print(results.ranked_names)\n",
    "plot = axl.Plot(results)\n",
    "plot.boxplot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p = plot.winplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot.payoff();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Axelrod's Tournament\n",
    "\n",
    "In 1980, Robert Axelrod (a political scientist) invited submissions to a computer tournament version of an iterated prisoners dilemma ([\"Effective Choice in the Prisoner's Dilemma\"](http://journals.sagepub.com/doi/abs/10.1177/002200278002400101)).\n",
    "\n",
    "- 15 strategies submitted. \n",
    "- Round robin tournament with 200 stages including a 16th player who played  randomly.\n",
    "- The winner (average score) was in fact a very simple strategy: Tit For Tat. This strategy starts by cooperating and then repeats the opponents previous move.\n",
    "\n",
    "The fact that Tit For Tat won garnered a lot of (still ongoing) research.  For an overview o of how to use axelrod to reproduce this first tournament, see [http://axelrod.readthedocs.io/en/stable/reference/overview_of_strategies.html#axelrod-s-first-tournament](http://axelrod.readthedocs.io/en/stable/reference/overview_of_strategies.html#axelrod-s-first-tournament).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "axelrod_first_tournament = [s() for s in axl.axelrod_first_strategies]\n",
    "\n",
    "number_of_strategies = len(axelrod_first_tournament)\n",
    "for player in axelrod_first_tournament:\n",
    "    print(player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tournament = axl.Tournament(\n",
    "    players=axelrod_first_tournament,\n",
    "    turns=200,\n",
    "    repetitions=5,\n",
    "    seed = 1, \n",
    ")\n",
    "results = tournament.play(progress_bar=False)\n",
    "for name in results.ranked_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot = axl.Plot(results)\n",
    "plot.boxplot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are over 200 strategies implemented in axelrod (see [https://axelrod.readthedocs.io/en/stable/reference/all_strategies.html](https://axelrod.readthedocs.io/en/stable/reference/all_strategies.html)).  Including some recent strategies that have done quite well in tournaments: \n",
    "\n",
    "\n",
    "Press, William H. and Freeman J. Dyson (2012), [Iterated prisoner’s dilemma contains strategies\n",
    "that dominate any evolutionary opponent](https://www.pnas.org/content/109/26/10409). Proceedings of the National Academy of Sciences,\n",
    "109, 10409–10413.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [ axl.ZDExtort2(), axl.ZDSet2(), axl.TitForTat()]\n",
    "tournament = axl.Tournament(\n",
    "    players=players,\n",
    "    turns=200,\n",
    "    repetitions=5,\n",
    ")\n",
    "results = tournament.play(progress_bar=False)\n",
    "for name in results.ranked_names:\n",
    "    print(name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Moran Process\n",
    "\n",
    "Given an initial population of players, the population is iterated in rounds consisting of:\n",
    "\n",
    "1. matches played between each pair of players, with the cumulative total scores recorded.\n",
    "2. a player is chosen to reproduce proportional to the player’s score in the round.\n",
    "3. a player is chosen at random to be replaced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "players = [axl.Cooperator(), axl.Defector(), axl.TitForTat(), axl.Grudger()]\n",
    "mp = axl.MoranProcess(players, turns=100)\n",
    "mp.play()\n",
    "print(\"Winning strategy: \", mp.winning_strategy_name)\n",
    "mp.populations_plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Moran Process with Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "players = [axl.Cooperator(), axl.Defector(),\n",
    "           axl.TitForTat(), axl.Grudger()]\n",
    "mp = axl.MoranProcess(players, turns=100, mutation_rate=0.1)\n",
    "for _ in mp:\n",
    "    if len(mp.population_distribution()) == 1:\n",
    "        break\n",
    "\n",
    "mp.populations_plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local Interactions\n",
    "\n",
    "Fix a 2x2 game.  Each agent plays this game with her neighbors in a network. \n",
    "\n",
    "At each step: \n",
    "\n",
    "1. One agent (the focal agent) is chosen at random to adopt a new strategy\n",
    "2. The focal agent chooses a new strategy based on how well her neighbors perform in the game: \n",
    "    * `imitation`: imitate the neighbor with the highest total score for that round\n",
    "    * `prob_imitation`: select a neighbor to imitate proportional to the  average payouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mesa import Model, Agent\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import SingleGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import widgets, interact, interact_manual\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create some games:\n",
    "\n",
    "A = np.array([[3, 0], [4, 1]])\n",
    "B = np.array([[3, 4], [0, 1]])\n",
    "pd = nash.Game(A, B)\n",
    "#print(pd)\n",
    "\n",
    "A = np.array([[3, 0], [6, 1]])\n",
    "B = np.array([[3, 6], [0, 1]])\n",
    "pd2 = nash.Game(A, B)\n",
    "#print(pd2)\n",
    "\n",
    "A = np.array([[1, 0], [0, 1]])\n",
    "B = np.array([[1, 0], [0, 1]])\n",
    "coord = nash.Game(A, B)\n",
    "#print(coord)\n",
    "\n",
    "A = np.array([[2, 0], [0, 1]])\n",
    "B = np.array([[2, 0], [0, 1]])\n",
    "hilo = nash.Game(A, B)\n",
    "#print(hilo)\n",
    "\n",
    "\n",
    "A = np.array([[2, 0], [0, 1]])\n",
    "B = np.array([[1, 0], [0, 2]])\n",
    "bos = nash.Game(A, B)\n",
    "#print(bos)\n",
    "\n",
    "A = np.array([[4, 1], [3, 2]])\n",
    "B = np.array([[4, 3], [1, 2]])\n",
    "sh = nash.Game(A, B)\n",
    "#print(sh)\n",
    "\n",
    "A = np.array([[9, 0], [8, 7]])\n",
    "B = np.array([[9, 8], [0, 7]])\n",
    "sh2 = nash.Game(A, B)\n",
    "#print(str(sh2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fix two strategies\n",
    "S1 = np.array([1, 0])\n",
    "S2 = np.array([0, 1])\n",
    "\n",
    "class Player(Agent):\n",
    "    '''\n",
    "    A player for a game \n",
    "    '''\n",
    "    def __init__(self, unique_id, pos, model, strat):\n",
    "\n",
    "        super().__init__(unique_id, model)\n",
    "        self.pos = pos\n",
    "        self.strat = strat # fixed strategy to play in the game \n",
    "\n",
    "    def average_payout(self):\n",
    "        '''find the average payout when playing the game against all neighbors'''\n",
    "        neighbors = self.model.grid.neighbor_iter(self.pos)\n",
    "        return np.average([self.model.game[self.strat, n.strat][0] for n in neighbors])\n",
    "    \n",
    "    def total_payout(self):\n",
    "        '''find the total payout when playing the game against all neighbors'''\n",
    "        neighbors = self.model.grid.neighbor_iter(self.pos)\n",
    "        return np.sum([self.model.game[self.strat, n.strat][0] for n in neighbors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GameLatticeModel(Model):\n",
    "    '''\n",
    "    Play a fixed game on a lattice.\n",
    "    '''\n",
    "    def __init__(self, height, width, game, bias_S1, num_changes_per_step, mutation, update_type):\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.game = game\n",
    "        self.bias_S1 = bias_S1\n",
    "        self.update_type = update_type\n",
    "        self.num_changes_per_step = num_changes_per_step\n",
    "        self.mutation = mutation\n",
    "        \n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = SingleGrid(height, width, torus=True)\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "             {\"Percent S1\": lambda m: np.sum([1 for a in m.schedule.agents \n",
    "                                              if  np.array_equal(a.strat, S1)]) / m.schedule.get_agent_count()}             )\n",
    "        self.running = True\n",
    "        \n",
    "        # Set up agents\n",
    "        agent_id = 0\n",
    "        for cell in self.grid.coord_iter():\n",
    "            _,x,y = cell\n",
    "            strat = S1 if random.random() < self.bias_S1 else S2\n",
    "            agent = Player(agent_id, (x, y), self, strat)\n",
    "            self.grid.position_agent(agent, x=x, y=y)\n",
    "            self.schedule.add(agent)\n",
    "            agent_id += 1\n",
    "        \n",
    "    def step(self):\n",
    "        for i in range(self.num_changes_per_step):\n",
    "            \n",
    "            # choose a random agent\n",
    "            focal_agent = np.random.choice(self.schedule.agents)\n",
    "            \n",
    "            # find all the neighbors of the agent\n",
    "            neighbors = self.grid.get_neighbors(focal_agent.pos, moore=True)\n",
    "            \n",
    "            \n",
    "            if self.update_type == 'imitator':\n",
    "                # imitate most successful neighbor\n",
    "                total_payouts  = {a: a.total_payout() for a in neighbors}\n",
    "\n",
    "                max_payout = max(total_payouts.values())\n",
    "\n",
    "                strat_to_imitate = [a.strat for a in total_payouts.keys() if total_payouts[a] == max_payout][0]\n",
    "\n",
    "            if self.update_type == 'prob_imitator':\n",
    "                \n",
    "                # get the average payouts for each neighbor\n",
    "                average_payouts = [a.average_payout() for a in neighbors]\n",
    "                total_average_payouts = np.sum(average_payouts)\n",
    "                \n",
    "                # probabilities for each neighbor\n",
    "                neighbor_probs = [n.average_payout() / total_average_payouts for n in neighbors]\n",
    "                \n",
    "                # probabilistically imitate most successful neighbor \n",
    "                strat_to_imitate = np.random.choice(neighbors, 1, p=neighbor_probs)[0].strat\n",
    "            \n",
    "            \n",
    "            # mutations\n",
    "            other_strat = S2 if np.array_equal(strat_to_imitate, S1) else S1\n",
    "            \n",
    "            if random.random() < self.mutation:\n",
    "                focal_agent.strat = other_strat\n",
    "            else: \n",
    "                focal_agent.strat = strat_to_imitate\n",
    "            \n",
    "            self.datacollector.collect(self)\n",
    "            \n",
    "            # stop running if all agents have the same strategy\n",
    "            if all([np.array_equal(a.strat, S1) for a in self.schedule.agents]) or all([np.array_equal(a.strat, S2) for a in self.schedule.agents]):\n",
    "                self.running=False\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Visualization\n",
    "\n",
    "height, width = 20, 20 \n",
    "game = pd\n",
    "bias_S1 = 0.5\n",
    "mutation = 0.0\n",
    "update_type = 'prob_imitator'\n",
    "num_changes_per_step = 100\n",
    "model = GameLatticeModel(height, width, \n",
    "                         game, bias_S1, \n",
    "                         num_changes_per_step, \n",
    "                         mutation, update_type)\n",
    "for i in range(50):\n",
    "# initialize the model\n",
    "    model.step()\n",
    "    if not model.running:\n",
    "        break\n",
    "        \n",
    "model_out = model.datacollector.get_model_vars_dataframe()\n",
    "model_out.plot();"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
